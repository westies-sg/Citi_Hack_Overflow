{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook help us scrape the website and put into our database\n",
        "\n",
        "\n",
        "> Indented block:\n",
        "\n"
      ],
      "metadata": {
        "id": "EcoEDCsJpBG6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up"
      ],
      "metadata": {
        "id": "i3rmZlgg0RsI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install dependencies"
      ],
      "metadata": {
        "id": "khCtKh6eDzh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain==0.0.189\n",
        "!pip install pinecone-client\n",
        "!pip install openai\n",
        "!pip install tiktoken\n",
        "!pip install nest_asyncio"
      ],
      "metadata": {
        "id": "mxFhFfKzRgpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up OpenAI API key"
      ],
      "metadata": {
        "id": "oU2eHKKCD4lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\""
      ],
      "metadata": {
        "id": "hOiNazy2SSPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up Pinecone API keys"
      ],
      "metadata": {
        "id": "6xUZg07MMvoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone\n",
        "\n",
        "# initialize pinecone\n",
        "pinecone.init(\n",
        "    api_key=\"PINECONE_API_KEY\",  # find at app.pinecone.io\n",
        "    environment=\"ENVIRONMENT_NAME\"  # next to api key in console\n",
        ")"
      ],
      "metadata": {
        "id": "7hai7fChMzw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Index"
      ],
      "metadata": {
        "id": "vCnFhGb40ZxR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load data from Web**\n",
        "\n",
        "Extends from the WebBaseLoader, this will load a sitemap from a given URL, and then scrape and load all the pages in the sitemap, returning each page as a document.\n",
        "\n",
        "The scraping is done concurrently, using WebBaseLoader. There are reasonable limits to concurrent requests, defaulting to 2 per second.\n",
        "\n",
        "Link to the [documentation](https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/sitemap.html)"
      ],
      "metadata": {
        "id": "kNrHppQSEQU2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcUaA9YWRS2D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a957320d-f6e7-4513-cec9-361264a14d8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching pages: 100%|##########| 505/505 [03:19<00:00,  2.53it/s]\n"
          ]
        }
      ],
      "source": [
        "# fixes a bug with asyncio and jupyter\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from langchain.document_loaders.sitemap import SitemapLoader\n",
        "\n",
        "loader = SitemapLoader(\n",
        "    \"https://ind.nl/sitemap.xml\",\n",
        "    filter_urls=[\"https://ind.nl/en\"]\n",
        ")\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split the text from docs into smaller chunks**\n",
        "\n",
        "There are many ways to split the text. We are using the text splitter that is recommended for generic texts. For more ways to slit the text check the [documentation](https://python.langchain.com/en/latest/modules/indexes/text_splitters.html)"
      ],
      "metadata": {
        "id": "N0Q03G2HG-6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1200,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        ")\n",
        "\n",
        "docs_chunks = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "DV9zorYiHAzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create embeddings"
      ],
      "metadata": {
        "id": "BtIKffZiFdpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "KK-LlnZJFPMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating a vectorstore**\n",
        "\n",
        "A vectorstore stores Documents and associated embeddings, and provides fast ways to look up relevant Documents by embeddings.\n",
        "\n",
        "There are many ways to create a vectorstore. We are going to use Pinecone. For other types of vectorstores visit the [documentation](https://python.langchain.com/en/latest/modules/indexes/vectorstores.html)\n",
        "\n",
        "First you need to go to [Pinecone](https://www.pinecone.io/) and create an index there. Then type the index name in \"index_name\""
      ],
      "metadata": {
        "id": "5sY05f0sFl_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Pinecone\n",
        "\n",
        "index_name = \"ind\"\n",
        "\n",
        "# #create a new index\n",
        "docsearch = Pinecone.from_documents(docs_chunks, embeddings, index_name=index_name)\n",
        "\n",
        "# if you already have an index, you can load it like this\n",
        "#docsearch = Pinecone.from_existing_index(index_name, embeddings)\n"
      ],
      "metadata": {
        "id": "cng7EmkbLyBb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}